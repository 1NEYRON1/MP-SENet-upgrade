{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MPNet Evaluation on VoiceBank+DEMAND (PESQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from models.mpnet.discriminator import cal_pesq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import AttrDict\n",
        "from models.mpnet.model import MPNet\n",
        "from utils.dataset import mag_pha_stft, mag_pha_istft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n",
            "Segment size: 16000 samples (1.00s)\n"
          ]
        }
      ],
      "source": [
        "CHECKPOINT_PATH = \"experiments/best_pesq.pt\"\n",
        "CONFIG_PATH = \"models/mpnet/config.json\"\n",
        "\n",
        "TESTSET_CLEAN_DIR = \"VoiceBank+DEMAND/wavs_clean\"\n",
        "TESTSET_NOISY_DIR = \"VoiceBank+DEMAND/wavs_noisy\"\n",
        "TEST_LIST_FILE = \"VoiceBank+DEMAND/test.txt\"\n",
        "\n",
        "# Override segment_size (16kHz: 0.5s=8000, 0.75s=12000, 1.0s=16000)\n",
        "SEGMENT_SIZE = 16000\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Segment size: {SEGMENT_SIZE} samples ({SEGMENT_SIZE/16000:.2f}s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded: 2,263,372 params\n",
            "Checkpoint epoch: 27, best_pesq: 3.620\n"
          ]
        }
      ],
      "source": [
        "with open(CONFIG_PATH) as f:\n",
        "    h = AttrDict(json.load(f))\n",
        "\n",
        "h.segment_size = SEGMENT_SIZE\n",
        "\n",
        "model = MPNet(h, num_tsblocks=h.num_tsconformers).to(device)\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded: {sum(p.numel() for p in model.parameters()):,} params\")\n",
        "print(f\"Checkpoint epoch: {checkpoint.get('epoch', 'N/A')}, best_pesq: {checkpoint.get('best_pesq', 'N/A'):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test files: 824\n"
          ]
        }
      ],
      "source": [
        "with open(TEST_LIST_FILE) as f:\n",
        "    test_files = [line.strip().split(\"|\")[0] for line in f if line.strip()]\n",
        "print(f\"Test files: {len(test_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def denoise(noisy_wav):\n",
        "    noisy = torch.FloatTensor(noisy_wav).to(device)\n",
        "    norm = torch.sqrt(len(noisy) / torch.sum(noisy ** 2.0))\n",
        "    noisy = (noisy * norm).unsqueeze(0)\n",
        "    \n",
        "    noisy_amp, noisy_pha, _ = mag_pha_stft(noisy, h.n_fft, h.hop_size, h.win_size, h.compress_factor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        amp_g, pha_g, _ = model(noisy_amp, noisy_pha)\n",
        "    \n",
        "    audio_g = mag_pha_istft(amp_g, pha_g, h.n_fft, h.hop_size, h.win_size, h.compress_factor)\n",
        "    return (audio_g / norm).squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e3c39eba72741f9988c38c2906714d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/824 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pesq_enhanced, pesq_noisy = [], []\n",
        "\n",
        "for filename in tqdm(test_files):\n",
        "    clean_path = os.path.join(TESTSET_CLEAN_DIR, filename + \".wav\")\n",
        "    noisy_path = os.path.join(TESTSET_NOISY_DIR, filename + \".wav\")\n",
        "    \n",
        "    clean_wav, _ = librosa.load(clean_path, sr=h.sampling_rate)\n",
        "    noisy_wav, _ = librosa.load(noisy_path, sr=h.sampling_rate)\n",
        "    \n",
        "    denoised_wav = denoise(noisy_wav)\n",
        "    \n",
        "    pesq_enhanced.append(cal_pesq(clean_wav, denoised_wav, h.sampling_rate))\n",
        "    # pesq_noisy.append(cal_pesq(clean_wav, noisy_wav, h.sampling_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated: 824 files\n",
            "\n",
            "PESQ Noisy: 1.9707\n",
            "PESQ Enhanced: 3.3902\n"
          ]
        }
      ],
      "source": [
        "print(f\"Evaluated: {len(pesq_enhanced)} files\")\n",
        "print(f\"\\nPESQ Noisy: {np.mean(pesq_noisy):.4f}\")\n",
        "print(f\"PESQ Enhanced: {np.mean(pesq_enhanced):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
