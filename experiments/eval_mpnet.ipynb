{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MPNet Evaluation on VoiceBank+DEMAND (PESQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdiscriminator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cal_pesq\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'models'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from models.discriminator import cal_pesq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from env import AttrDict\n",
        "from models.model import MPNet\n",
        "from dataset import mag_pha_stft, mag_pha_istft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "CHECKPOINT_PATH = \"best_ckpt/g_best_vb\"\n",
        "CONFIG_PATH = \"best_ckpt/config.json\"\n",
        "\n",
        "TESTSET_CLEAN_DIR = \"../VoiceBank+DEMAND/wavs_clean\"\n",
        "TESTSET_NOISY_DIR = \"../VoiceBank+DEMAND/wavs_noisy\"\n",
        "TEST_LIST_FILE = \"../VoiceBank+DEMAND/test.txt\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded: 2,263,372 params\n"
          ]
        }
      ],
      "source": [
        "with open(CONFIG_PATH) as f:\n",
        "    h = AttrDict(json.load(f))\n",
        "\n",
        "model = MPNet(h, num_tsblocks=4).to(device)\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
        "model.load_state_dict(checkpoint[\"generator\"])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded: {sum(p.numel() for p in model.parameters()):,} params\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test files: 824\n"
          ]
        }
      ],
      "source": [
        "with open(TEST_LIST_FILE) as f:\n",
        "    test_files = [line.strip().split(\"|\")[0] for line in f if line.strip()]\n",
        "print(f\"Test files: {len(test_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def denoise(noisy_wav):\n",
        "    noisy = torch.FloatTensor(noisy_wav).to(device)\n",
        "    norm = torch.sqrt(len(noisy) / torch.sum(noisy ** 2.0))\n",
        "    noisy = (noisy * norm).unsqueeze(0)\n",
        "    \n",
        "    noisy_amp, noisy_pha, _ = mag_pha_stft(noisy, h.n_fft, h.hop_size, h.win_size, h.compress_factor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        amp_g, pha_g, _ = model(noisy_amp, noisy_pha)\n",
        "    \n",
        "    audio_g = mag_pha_istft(amp_g, pha_g, h.n_fft, h.hop_size, h.win_size, h.compress_factor)\n",
        "    return (audio_g / norm).squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35993d385e48442285b8df3c301bbc9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/824 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pesq_enhanced, pesq_noisy = [], []\n",
        "\n",
        "for filename in tqdm(test_files):\n",
        "    clean_path = os.path.join(TESTSET_CLEAN_DIR, filename + \".wav\")\n",
        "    noisy_path = os.path.join(TESTSET_NOISY_DIR, filename + \".wav\")\n",
        "    \n",
        "    clean_wav, _ = librosa.load(clean_path, sr=h.sampling_rate)\n",
        "    noisy_wav, _ = librosa.load(noisy_path, sr=h.sampling_rate)\n",
        "    \n",
        "    denoised_wav = denoise(noisy_wav)\n",
        "    \n",
        "    pesq_enhanced.append(cal_pesq(clean_wav, denoised_wav, h.sampling_rate))\n",
        "    pesq_noisy.append(cal_pesq(clean_wav, noisy_wav, h.sampling_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated: 824 files\n",
            "\n",
            "PESQ Noisy: 1.9707\n",
            "PESQ Enhanced: 3.6009\n"
          ]
        }
      ],
      "source": [
        "print(f\"Evaluated: {len(pesq_enhanced)} files\")\n",
        "print(f\"\\nPESQ Noisy: {np.mean(pesq_noisy):.4f}\")\n",
        "print(f\"PESQ Enhanced: {np.mean(pesq_enhanced):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
