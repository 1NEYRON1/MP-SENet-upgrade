{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1058efe8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "45d324d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from rat_models import GTCRN_RAT, MPNet_RAT\n",
        "from models.gtcrn import GTCRN\n",
        "from models import MPNet\n",
        "from experiments.min_gru import MinMPNet\n",
        "from utils import count_parameters, VCTKDatasetFromList, load_config, mag_pha_stft, mag_pha_istft, compute_pesq, compute_sisnr\n",
        "from train.gtcrn import validate_epoch, HybridLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2ab40748",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded GTCRN, params: 23,669\n",
            "Loaded GTCRN_RAT (chunk=4), params: 24,757\n",
            "Loaded GTCRN_RAT (chunk=8), params: 24,757\n",
            "Loaded GTCRN_RAT (chunk=16), params: 24,757\n",
            "Loaded GTCRN_RAT (chunk=32), params: 24,757\n",
            "Loaded GTCRN_RAT (chunk=64), params: 24,757\n",
            "Loaded MPNet, params: 2,263,372\n",
            "Loaded MinMPNet, params: 1,333,580\n",
            "Loaded MPNet_RAT (chunk=4), params: 1,062,732\n",
            "Loaded MPNet_RAT (chunk=8), params: 1,062,732\n",
            "Loaded MPNet_RAT (chunk=16), params: 1,062,732\n",
            "Loaded MPNet_RAT (chunk=32), params: 1,062,732\n",
            "Loaded MPNet_RAT (chunk=64), params: 1,062,732\n"
          ]
        }
      ],
      "source": [
        "mpnet_config = load_config(\"../../models/mpnet/config.json\")\n",
        "\n",
        "models_config = {\n",
        "    \"GTCRN\": (GTCRN, {}, \"checkpoints/gtcrn/best.pt\"),\n",
        "    \"GTCRN_RAT (chunk=4)\": (GTCRN_RAT, {\"chunk_size\": 4}, \"checkpoints/gtcrn_rat/chunk_4/best.pt\"),\n",
        "    \"GTCRN_RAT (chunk=8)\": (GTCRN_RAT, {\"chunk_size\": 8}, \"checkpoints/gtcrn_rat/chunk_8/best.pt\"),\n",
        "    \"GTCRN_RAT (chunk=16)\": (GTCRN_RAT, {\"chunk_size\": 16}, \"checkpoints/gtcrn_rat/chunk_16/best.pt\"),\n",
        "    \"GTCRN_RAT (chunk=32)\": (GTCRN_RAT, {\"chunk_size\": 32}, \"checkpoints/gtcrn_rat/chunk_32/best.pt\"),\n",
        "    \"GTCRN_RAT (chunk=64)\": (GTCRN_RAT, {\"chunk_size\": 64}, \"checkpoints/gtcrn_rat/chunk_64/best.pt\"),\n",
        "    \"MPNet\": (MPNet, {\"h\": mpnet_config}, \"checkpoints/mpnet/best.pt\"),\n",
        "    \"MinMPNet\": (MinMPNet, {\"h\": mpnet_config}, \"checkpoints/min_mpnet/best_pesq.pt\"),\n",
        "    \"MPNet_RAT (chunk=4)\": (MPNet_RAT, {\"h\": mpnet_config, \"chunk_size\": 4}, \"checkpoints/mpnet_rat/chunk_4/best.pt\"),\n",
        "    \"MPNet_RAT (chunk=8)\": (MPNet_RAT, {\"h\": mpnet_config, \"chunk_size\": 8}, \"checkpoints/mpnet_rat/chunk_8/best.pt\"),\n",
        "    \"MPNet_RAT (chunk=16)\": (MPNet_RAT, {\"h\": mpnet_config, \"chunk_size\": 16}, \"checkpoints/mpnet_rat/chunk_16/best.pt\"),\n",
        "    \"MPNet_RAT (chunk=32)\": (MPNet_RAT, {\"h\": mpnet_config, \"chunk_size\": 32}, \"checkpoints/mpnet_rat/chunk_32/best.pt\"),\n",
        "    \"MPNet_RAT (chunk=64)\": (MPNet_RAT, {\"h\": mpnet_config, \"chunk_size\": 64}, \"checkpoints/mpnet_rat/chunk_64/best.pt\"),\n",
        "}\n",
        "\n",
        "import os\n",
        "\n",
        "models = {}\n",
        "for name, (model_cls, kwargs, ckpt_path) in models_config.items():\n",
        "    model = model_cls(**kwargs)\n",
        "    if os.path.isfile(ckpt_path):\n",
        "        checkpoint = torch.load(ckpt_path, map_location=\"cpu\", weights_only=True)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    model.eval()\n",
        "    models[name] = model\n",
        "    print(f\"Loaded {name}, params: {count_parameters(model):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ab6f2fbd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 824 files from ../../VoiceBank+DEMAND/test.txt\n",
            "Loaded 824 files from ../../VoiceBank+DEMAND/test.txt\n"
          ]
        }
      ],
      "source": [
        "base_dir = \"../../VoiceBank+DEMAND/\"\n",
        "test_dataset = VCTKDatasetFromList(\n",
        "    file_list=base_dir + \"test.txt\",\n",
        "    clean_dir=base_dir + \"wavs_clean\",\n",
        "    noisy_dir=base_dir + \"wavs_noisy\",\n",
        "    segment_len=None,\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "test_dataset_audio = VCTKDatasetFromList(\n",
        "    file_list=base_dir + \"test.txt\",\n",
        "    clean_dir=base_dir + \"wavs_clean\",\n",
        "    noisy_dir=base_dir + \"wavs_noisy\",\n",
        "    segment_len=None,\n",
        "    return_audio=True,\n",
        ")\n",
        "test_loader_audio = DataLoader(test_dataset_audio, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25d3897",
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name, model in models.items():\n",
        "    if \"mpnet\" in model_name.lower():\n",
        "        h = mpnet_config\n",
        "        model = model.to(\"cpu\")\n",
        "        pesq_scores, sisnr_scores = [], []\n",
        "        with torch.no_grad():\n",
        "            for noisy_audio, clean_audio in test_loader_audio:\n",
        "                noisy_audio = noisy_audio.unsqueeze(0)\n",
        "                clean_audio = clean_audio.unsqueeze(0)\n",
        "                noisy_mag, noisy_pha, _ = mag_pha_stft(\n",
        "                    noisy_audio, h.n_fft, h.hop_size, h.win_size, getattr(h, \"compress_factor\", 1.0)\n",
        "                )\n",
        "                mag_g, pha_g, _ = model(noisy_mag, noisy_pha)\n",
        "                audio_g = mag_pha_istft(\n",
        "                    mag_g, pha_g, h.n_fft, h.hop_size, h.win_size, getattr(h, \"compress_factor\", 1.0)\n",
        "                )\n",
        "                pesq_scores.append(compute_pesq(clean_audio[0].cpu(), audio_g[0].cpu()))\n",
        "                sisnr_scores.append(compute_sisnr(clean_audio, audio_g).item())\n",
        "        pesq_mean = sum(pesq_scores) / len(pesq_scores) if pesq_scores else 0.0\n",
        "        sisnr_mean = sum(sisnr_scores) / len(sisnr_scores) if sisnr_scores else 0.0\n",
        "        print(f\"{model_name} PESQ: {pesq_mean:.3f}, SI-SNR: {sisnr_mean:.2f} dB\")\n",
        "    else:\n",
        "        val_loss, metrics = validate_epoch(model, test_loader, HybridLoss(), \"cpu\", verbose=False)\n",
        "        print(f\"{model_name} PESQ: {metrics['pesq']:.3f}, SI-SNR: {metrics['sisnr']:.2f} dB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61df086d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
